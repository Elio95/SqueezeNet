{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG and VGGSqueez.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ug-fs0E4xK7X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Squeez_VGG_19 ICLR"
      ]
    },
    {
      "metadata": {
        "id": "eX3N37bwh2Zj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = [\n",
        "    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
        "    'vgg19_bn', 'vgg19',\n",
        "]\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
        "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
        "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
        "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
        "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
        "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
        "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
        "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, features, num_classes=1000, init_weights=True):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = features\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=1, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=1, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "cfg = {\n",
        "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "\n",
        "def vgg11(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 11-layer model (configuration \"A\")\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['A']), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg11']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg11_bn(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['A'], batch_norm=True), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg11_bn']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg13(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 13-layer model (configuration \"B\")\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['B']), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg13']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg13_bn(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['B'], batch_norm=True), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg13_bn']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg16(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 16-layer model (configuration \"D\")\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['D']), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg16']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg16_bn(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['D'], batch_norm=True), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg16_bn']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg19(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 19-layer model (configuration \"E\")\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['E']), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg19']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg19_bn(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['E'], batch_norm=True), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg19_bn']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rpvnlUQJh2Od",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq2=vgg19(pretrained=False,num_classes=10).cuda()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BUgmfyIqh17R",
        "colab_type": "code",
        "outputId": "9fc482f7-d450-4d6c-bf8e-fbe9a5c4ba5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transforms.Resize((224,224))\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((224,224)),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "     ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 170205184/170498071 [00:26<00:00, 5288293.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tLRL250Ih_Xs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(seq2.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKFEhTMnh_tp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer.zero_grad()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KWsCDWGZCgA5",
        "colab_type": "code",
        "outputId": "2b2ec1f8-1a3a-4f04-a23f-27a29678782b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(10):# loop over the dataset multiple times\n",
        "  \n",
        "    print(epoch)\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = seq2(inputs.cuda())\n",
        "        loss = criterion(outputs.cuda(), labels.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))e\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "[1,  2000] loss: 2.180\n",
            "[1,  4000] loss: 2.006\n",
            "[1,  6000] loss: 1.905\n",
            "[1,  8000] loss: 1.844\n",
            "[1, 10000] loss: 1.784\n",
            "[1, 12000] loss: 1.744\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Tfv-cWe3iKlP",
        "colab_type": "code",
        "outputId": "c8f15ff5-38bb-4846-acab-8a342421ab46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "outputs = seq2(images.cuda())\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = seq2(images.cuda())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.cuda()).sum().item()\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "\n",
        "acc=100 * correct / total\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 39 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RVItqf18qxjz",
        "colab_type": "code",
        "outputId": "73762afe-22ea-4be7-9537-8a2f3132dfb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1072
        }
      },
      "cell_type": "code",
      "source": [
        "# model summary \n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "seq2.cuda()\n",
        "summary(seq2, (3, 224, 224))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 226, 226]             256\n",
            "              ReLU-2         [-1, 64, 226, 226]               0\n",
            "            Conv2d-3         [-1, 64, 228, 228]           4,160\n",
            "              ReLU-4         [-1, 64, 228, 228]               0\n",
            "         MaxPool2d-5         [-1, 64, 114, 114]               0\n",
            "            Conv2d-6        [-1, 128, 116, 116]           8,320\n",
            "              ReLU-7        [-1, 128, 116, 116]               0\n",
            "            Conv2d-8        [-1, 128, 118, 118]          16,512\n",
            "              ReLU-9        [-1, 128, 118, 118]               0\n",
            "        MaxPool2d-10          [-1, 128, 59, 59]               0\n",
            "           Conv2d-11          [-1, 256, 61, 61]          33,024\n",
            "             ReLU-12          [-1, 256, 61, 61]               0\n",
            "           Conv2d-13          [-1, 256, 63, 63]          65,792\n",
            "             ReLU-14          [-1, 256, 63, 63]               0\n",
            "           Conv2d-15          [-1, 256, 65, 65]          65,792\n",
            "             ReLU-16          [-1, 256, 65, 65]               0\n",
            "           Conv2d-17          [-1, 256, 67, 67]          65,792\n",
            "             ReLU-18          [-1, 256, 67, 67]               0\n",
            "        MaxPool2d-19          [-1, 256, 34, 34]               0\n",
            "           Conv2d-20          [-1, 512, 36, 36]         131,584\n",
            "             ReLU-21          [-1, 512, 36, 36]               0\n",
            "           Conv2d-22          [-1, 512, 38, 38]         262,656\n",
            "             ReLU-23          [-1, 512, 38, 38]               0\n",
            "           Conv2d-24          [-1, 512, 40, 40]         262,656\n",
            "             ReLU-25          [-1, 512, 40, 40]               0\n",
            "           Conv2d-26          [-1, 512, 42, 42]         262,656\n",
            "             ReLU-27          [-1, 512, 42, 42]               0\n",
            "        MaxPool2d-28          [-1, 512, 21, 21]               0\n",
            "           Conv2d-29          [-1, 512, 23, 23]         262,656\n",
            "             ReLU-30          [-1, 512, 23, 23]               0\n",
            "           Conv2d-31          [-1, 512, 25, 25]         262,656\n",
            "             ReLU-32          [-1, 512, 25, 25]               0\n",
            "           Conv2d-33          [-1, 512, 27, 27]         262,656\n",
            "             ReLU-34          [-1, 512, 27, 27]               0\n",
            "           Conv2d-35          [-1, 512, 29, 29]         262,656\n",
            "             ReLU-36          [-1, 512, 29, 29]               0\n",
            "        MaxPool2d-37          [-1, 512, 15, 15]               0\n",
            "AdaptiveAvgPool2d-38            [-1, 512, 7, 7]               0\n",
            "           Linear-39                 [-1, 4096]     102,764,544\n",
            "             ReLU-40                 [-1, 4096]               0\n",
            "          Dropout-41                 [-1, 4096]               0\n",
            "           Linear-42                 [-1, 4096]      16,781,312\n",
            "             ReLU-43                 [-1, 4096]               0\n",
            "          Dropout-44                 [-1, 4096]               0\n",
            "           Linear-45                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 121,816,650\n",
            "Trainable params: 121,816,650\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 302.15\n",
            "Params size (MB): 464.69\n",
            "Estimated Total Size (MB): 767.42\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VZoUfJXKyFrJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#VGG19 ICLR"
      ]
    },
    {
      "metadata": {
        "id": "k-tqhYbIJxZC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lKDuzoXuNqFr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "\n",
        "__all__ = [\n",
        "    'VGG', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn',\n",
        "    'vgg19_bn', 'vgg19',\n",
        "]\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'vgg11': 'https://download.pytorch.org/models/vgg11-bbd30ac9.pth',\n",
        "    'vgg13': 'https://download.pytorch.org/models/vgg13-c768596a.pth',\n",
        "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
        "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
        "    'vgg11_bn': 'https://download.pytorch.org/models/vgg11_bn-6002323d.pth',\n",
        "    'vgg13_bn': 'https://download.pytorch.org/models/vgg13_bn-abd245e5.pth',\n",
        "    'vgg16_bn': 'https://download.pytorch.org/models/vgg16_bn-6c64b313.pth',\n",
        "    'vgg19_bn': 'https://download.pytorch.org/models/vgg19_bn-c79401a0.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "\n",
        "    def __init__(self, features, num_classes=1000, init_weights=True):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = features\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "cfg = {\n",
        "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "\n",
        "def vgg11(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 11-layer model (configuration \"A\")\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['A']), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg11']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg11_bn(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 11-layer model (configuration \"A\") with batch normalization\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['A'], batch_norm=True), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg11_bn']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg13(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 13-layer model (configuration \"B\")\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['B']), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg13']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg13_bn(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 13-layer model (configuration \"B\") with batch normalization\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['B'], batch_norm=True), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg13_bn']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg16(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 16-layer model (configuration \"D\")\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['D']), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg16']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg16_bn(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 16-layer model (configuration \"D\") with batch normalization\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['D'], batch_norm=True), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg16_bn']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg19(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 19-layer model (configuration \"E\")\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['E']), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg19']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg19_bn(pretrained=False, **kwargs):\n",
        "    \"\"\"VGG 19-layer model (configuration 'E') with batch normalization\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    if pretrained:\n",
        "        kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['E'], batch_norm=True), **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['vgg19_bn']))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JNYY3eotJ0Bl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xLSdy1mzq97g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seq3=vgg19(pretrained=False,num_classes=10).cuda()\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(seq3.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FRn9zCb7r2Pk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "    print(epoch)\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = seq3(inputs.cuda())\n",
        "        loss = criterion(outputs.cuda(), labels.cuda())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NbD4eHpSOnn5",
        "colab_type": "code",
        "outputId": "5c5b2d66-dee3-4c51-bf40-ac709d414e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "outputs = seq3(images.cuda())\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = seq3(images.cuda())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.cuda()).sum().item()\n",
        "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
        "    100 * correct / total))\n",
        "\n",
        "acc=100 * correct / total"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 79 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bPjPJ4ehAgFC",
        "colab_type": "code",
        "outputId": "3ab9722e-1359-4b2e-8ff1-bf63f60e157a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1072
        }
      },
      "cell_type": "code",
      "source": [
        "# model summary \n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "seq3.cuda()\n",
        "summary(seq3, (3, 224, 224))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
            "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-7        [-1, 128, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-9        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
            "             ReLU-12          [-1, 256, 56, 56]               0\n",
            "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-16          [-1, 256, 56, 56]               0\n",
            "           Conv2d-17          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-18          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-19          [-1, 256, 28, 28]               0\n",
            "           Conv2d-20          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-21          [-1, 512, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-23          [-1, 512, 28, 28]               0\n",
            "           Conv2d-24          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-25          [-1, 512, 28, 28]               0\n",
            "           Conv2d-26          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-27          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-30          [-1, 512, 14, 14]               0\n",
            "           Conv2d-31          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-32          [-1, 512, 14, 14]               0\n",
            "           Conv2d-33          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-34          [-1, 512, 14, 14]               0\n",
            "           Conv2d-35          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-36          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-37            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-38            [-1, 512, 7, 7]               0\n",
            "           Linear-39                 [-1, 4096]     102,764,544\n",
            "             ReLU-40                 [-1, 4096]               0\n",
            "          Dropout-41                 [-1, 4096]               0\n",
            "           Linear-42                 [-1, 4096]      16,781,312\n",
            "             ReLU-43                 [-1, 4096]               0\n",
            "          Dropout-44                 [-1, 4096]               0\n",
            "           Linear-45                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 139,611,210\n",
            "Trainable params: 139,611,210\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 238.68\n",
            "Params size (MB): 532.57\n",
            "Estimated Total Size (MB): 771.83\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}